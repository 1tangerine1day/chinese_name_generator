{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f=  open ('./char_embedding.pkl', 'rb')\n",
    "dict_char = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_char_idx = dict()\n",
    "dict_idx_char = dict()\n",
    "for i, char in enumerate(dict_char.keys()):\n",
    "    dict_char_idx[char] = i\n",
    "for i, char in enumerate(dict_char.keys()):\n",
    "    dict_idx_char[i] = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable as V\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import log_softmax \n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.gru = nn.GRU(self.input_size, self.hidden_size,dropout = 0.5)\n",
    "        self.h2o = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax() \n",
    "    def forward(self, input):\n",
    "        out,_ = self.gru(input)\n",
    "        out = self.h2o(out).squeeze(0).squeeze(0)\n",
    "        output = self.softmax(out)\n",
    "        return output\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_name_ran(char1) :\n",
    "    char2=''\n",
    "    char3=''\n",
    "    char4='' \n",
    "    char2 = predict_char_ran10(char1)\n",
    "    while char2 == '。':\n",
    "        char2 = predict_char_ran10(char1)\n",
    "    if char2 != '。' :\n",
    "        char3 = predict_char_ran10(char2)\n",
    "    if char3 != '。' :\n",
    "        char4 = predict_char(char3)\n",
    "\n",
    "    name = char1 + char2 + char3 + char4    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_char(char):\n",
    "    test = dict_char[char]\n",
    "    test_tensor = torch.from_numpy(test).unsqueeze(0).unsqueeze(0).cuda()\n",
    "    #print (test_tensor.shape)\n",
    "    gen_test = model(test_tensor)\n",
    " \n",
    "    k = int(torch.max(gen_test,0)[1])\n",
    "    \n",
    "    return dict_idx_char[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_char_ran10(char): \n",
    "    test = dict_char[char] \n",
    "    test_tensor = torch.from_numpy(test).unsqueeze(0).unsqueeze(0).cuda() \n",
    "    gen_test = model(test_tensor) \n",
    "    x = torch.topk(gen_test,10)[1] \n",
    "    p = torch.topk(gen_test,10)[0] \n",
    "    p = softmax(p.float())\n",
    "    \n",
    "    x2 = []\n",
    "    for i in list(x):\n",
    "        x2.append(int(i)) \n",
    "\n",
    "    sum = 0\n",
    "    p2 = []\n",
    "    for i in list(p):\n",
    "        p2.append(float(i))\n",
    "        sum += float(i) \n",
    "    \n",
    "    ac = 1-sum\n",
    "    p2[0] += ac\n",
    "    \n",
    "    k = np.random.choice(range(10) , p=p2)\n",
    "    index = x2[k]\n",
    "    return dict_idx_char[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = 256\n",
    "HIDDEN_DIM = 64\n",
    "TARGET_DIM = len(dict_char.keys())\n",
    "teacher_force = 0.87\n",
    "forget_end = 0.1\n",
    "\n",
    "model = RNN(INPUT_DIM, HIDDEN_DIM, TARGET_DIM).cuda()\n",
    "model = torch.load('model-none-max-31.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'林佳微。'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_name_ran('林')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
